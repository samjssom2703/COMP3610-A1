{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03a44ee",
   "metadata": {},
   "source": [
    "# **COMP 3610 - ASSIGNMENT 1**\n",
    "### _**Samuel Soman - 816039318**_\n",
    "Data Pipeline & Visualization Dashboard\n",
    "- This notebook builds an end-to-end data pipeline that ingests, transforms, and analyzes the NYC Yellow Taxi Trip dataset (January 2024). \n",
    "- We download the data programmatically, clean and validate it, perform SQL-based analysis with DuckDB, and prototype interactive visualizations for the Streamlit dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfeaf21",
   "metadata": {},
   "source": [
    "## _**Part 1: Data Ingestion & Storage**_\n",
    "This part contains Programmatic Download, Data Validation, File Organisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7056b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Libraries Imported Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import all libraries required for the assignment\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print('All Libraries Imported Successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608aeff7",
   "metadata": {},
   "source": [
    "### 1. Programmatic Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e2bd600",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIP_DATA_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\"\n",
    "ZONE_LOOKUP_URL = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "\n",
    "RAW_DIR = os.path.join(\"data\", \"raw\")\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "\n",
    "TRIP_DATA_PATH = os.path.join(RAW_DIR, \"yellow_tripdata_2024-01.parquet\")\n",
    "ZONE_LOOKUP_PATH = os.path.join(RAW_DIR, \"taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22c24ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet ...\n",
      "Saved to data\\raw\\yellow_tripdata_2024-01.parquet (47.6 MB)\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv ...\n",
      "Saved to data\\raw\\taxi_zone_lookup.csv (0.0 MB)\n"
     ]
    }
   ],
   "source": [
    "def download_file(url, dest_path):\n",
    "    if os.path.exists(dest_path):\n",
    "        print(f\"Already exists, skipping: {dest_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Downloading {url} ...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(dest_path, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "    size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n",
    "    print(f\"Saved to {dest_path} ({size_mb:.1f} MB)\")\n",
    "\n",
    "\n",
    "# Download both datasets\n",
    "download_file(TRIP_DATA_URL, TRIP_DATA_PATH)\n",
    "download_file(ZONE_LOOKUP_URL, ZONE_LOOKUP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd61a9f",
   "metadata": {},
   "source": [
    "### 2. Data Validation\n",
    "Implement validation checks that:\n",
    "    \n",
    "    a) Verify all expected columns exist in the dataset\n",
    "\n",
    "    b) Check that date columns are valid datetime types\n",
    "\n",
    "    c) Report total row count and print a summary to the console\n",
    "\n",
    "    d) Raise an exception or exit with an error message if validation fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e44914f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip data: data\\raw\\yellow_tripdata_2024-01.parquet (47.65 MB)\n",
      "Zone lookup: data\\raw\\taxi_zone_lookup.csv (0.01 MB)\n",
      "\n",
      "Trip dataset shape: (2964624, 19)\n",
      "Columns: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'Airport_fee']\n",
      "\n",
      "Zone lookup shape: (265, 4)\n",
      "Columns: ['LocationID', 'Borough', 'Zone', 'service_zone']\n"
     ]
    }
   ],
   "source": [
    "# Validate that the downloads completed successfully\n",
    "for label, path in [(\"Trip data\", TRIP_DATA_PATH), (\"Zone lookup\", ZONE_LOOKUP_PATH)]:\n",
    "    if os.path.exists(path):\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "        print(f\"{label}: {path} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"{label}: {path} NOT FOUND!\")\n",
    "\n",
    "# Validate parquet file is readable\n",
    "df_raw = pd.read_parquet(TRIP_DATA_PATH)\n",
    "print(f\"\\nTrip dataset shape: {df_raw.shape}\")\n",
    "print(f\"Columns: {list(df_raw.columns)}\")\n",
    "\n",
    "# Validate zone lookup CSV\n",
    "zone_df = pd.read_csv(ZONE_LOOKUP_PATH)\n",
    "print(f\"\\nZone lookup shape: {zone_df.shape}\")\n",
    "print(f\"Columns: {list(zone_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf80c1",
   "metadata": {},
   "source": [
    "### 3. File Organisation & Initial Inspection\n",
    "Save downloaded files to a data/raw/ directory. Include a .gitignore file that excludes the data directory from version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11dd2198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ directory structure:\n",
      "data/\n",
      "  raw/\n",
      "    taxi_zone_lookup.csv (0.01 MB)\n",
      "    yellow_tripdata_2024-01.parquet (47.65 MB)\n",
      "\n",
      "--- Data Types ---\n",
      "VendorID                          int32\n",
      "tpep_pickup_datetime     datetime64[us]\n",
      "tpep_dropoff_datetime    datetime64[us]\n",
      "passenger_count                 float64\n",
      "trip_distance                   float64\n",
      "RatecodeID                      float64\n",
      "store_and_fwd_flag               object\n",
      "PULocationID                      int32\n",
      "DOLocationID                      int32\n",
      "payment_type                      int64\n",
      "fare_amount                     float64\n",
      "extra                           float64\n",
      "mta_tax                         float64\n",
      "tip_amount                      float64\n",
      "tolls_amount                    float64\n",
      "improvement_surcharge           float64\n",
      "total_amount                    float64\n",
      "congestion_surcharge            float64\n",
      "Airport_fee                     float64\n",
      "dtype: object\n",
      "\n",
      "--- First 5 Rows ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 00:57:55</td>\n",
       "      <td>2024-01-01 01:17:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:03:00</td>\n",
       "      <td>2024-01-01 00:09:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:17:06</td>\n",
       "      <td>2024-01-01 00:35:01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:36:38</td>\n",
       "      <td>2024-01-01 00:44:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:46:51</td>\n",
       "      <td>2024-01-01 00:52:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2024-01-01 00:57:55   2024-01-01 01:17:43              1.0   \n",
       "1         1  2024-01-01 00:03:00   2024-01-01 00:09:36              1.0   \n",
       "2         1  2024-01-01 00:17:06   2024-01-01 00:35:01              1.0   \n",
       "3         1  2024-01-01 00:36:38   2024-01-01 00:44:56              1.0   \n",
       "4         1  2024-01-01 00:46:51   2024-01-01 00:52:57              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           1.72         1.0                  N           186            79   \n",
       "1           1.80         1.0                  N           140           236   \n",
       "2           4.70         1.0                  N           236            79   \n",
       "3           1.40         1.0                  N            79           211   \n",
       "4           0.80         1.0                  N           211           148   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2         17.7    1.0      0.5        0.00           0.0   \n",
       "1             1         10.0    3.5      0.5        3.75           0.0   \n",
       "2             1         23.3    3.5      0.5        3.00           0.0   \n",
       "3             1         10.0    3.5      0.5        2.00           0.0   \n",
       "4             1          7.9    3.5      0.5        3.20           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0         22.70                   2.5          0.0  \n",
       "1                    1.0         18.75                   2.5          0.0  \n",
       "2                    1.0         31.30                   2.5          0.0  \n",
       "3                    1.0         17.00                   2.5          0.0  \n",
       "4                    1.0         16.10                   2.5          0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"data/ directory structure:\")\n",
    "for root, dirs, files in os.walk(\"data\"):\n",
    "    level = root.replace(\"data\", \"\").count(os.sep)\n",
    "    indent = \"  \" * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    for f in files:\n",
    "        size_mb = os.path.getsize(os.path.join(root, f)) / (1024 * 1024)\n",
    "        print(f\"{indent}  {f} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\n--- Data Types ---\")\n",
    "print(df_raw.dtypes)\n",
    "\n",
    "print(\"\\n--- First 5 Rows ---\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55414b3",
   "metadata": {},
   "source": [
    "## _**Part 2: Data Transformation & Analysis**_\n",
    "This part covers Data Cleaning, Feature Engineering, Saving the Processed Dataset, and Running SQL queries with DuckDB."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
