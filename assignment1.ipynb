{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03a44ee",
   "metadata": {},
   "source": [
    "# **COMP 3610 - ASSIGNMENT 1**\n",
    "### _**Samuel Soman - 816039318**_\n",
    "Data Pipeline & Visualization Dashboard\n",
    "- This notebook builds an end-to-end data pipeline that ingests, transforms, and analyzes the NYC Yellow Taxi Trip dataset (January 2024). \n",
    "- We download the data programmatically, clean and validate it, perform SQL-based analysis with DuckDB, and prototype interactive visualizations for the Streamlit dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfeaf21",
   "metadata": {},
   "source": [
    "## _**Part 1: Data Ingestion & Storage**_\n",
    "This part contains Programmatic Download, Data Validation, File Organisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7056b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Libraries Imported Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import all libraries required for the assignment\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print('All Libraries Imported Successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608aeff7",
   "metadata": {},
   "source": [
    "### 1. Programmatic Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e2bd600",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIP_DATA_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\"\n",
    "ZONE_LOOKUP_URL = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "\n",
    "RAW_DIR = os.path.join(\"data\", \"raw\")\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "\n",
    "TRIP_DATA_PATH = os.path.join(RAW_DIR, \"yellow_tripdata_2024-01.parquet\")\n",
    "ZONE_LOOKUP_PATH = os.path.join(RAW_DIR, \"taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22c24ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet ...\n",
      "Saved to data\\raw\\yellow_tripdata_2024-01.parquet (47.6 MB)\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv ...\n",
      "Saved to data\\raw\\taxi_zone_lookup.csv (0.0 MB)\n"
     ]
    }
   ],
   "source": [
    "def download_file(url, dest_path):\n",
    "    if os.path.exists(dest_path):\n",
    "        print(f\"Already exists, skipping: {dest_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Downloading {url} ...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(dest_path, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "    size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n",
    "    print(f\"Saved to {dest_path} ({size_mb:.1f} MB)\")\n",
    "\n",
    "\n",
    "# Download both datasets\n",
    "download_file(TRIP_DATA_URL, TRIP_DATA_PATH)\n",
    "download_file(ZONE_LOOKUP_URL, ZONE_LOOKUP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd61a9f",
   "metadata": {},
   "source": [
    "### 2. Data Validation\n",
    "Implement validation checks that:\n",
    "    \n",
    "    a) Verify all expected columns exist in the dataset\n",
    "\n",
    "    b) Check that date columns are valid datetime types\n",
    "\n",
    "    c) Report total row count and print a summary to the console\n",
    "\n",
    "    d) Raise an exception or exit with an error message if validation fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e44914f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip data: data\\raw\\yellow_tripdata_2024-01.parquet (47.65 MB)\n",
      "Zone lookup: data\\raw\\taxi_zone_lookup.csv (0.01 MB)\n",
      "\n",
      "Trip dataset shape: (2964624, 19)\n",
      "Columns: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'Airport_fee']\n",
      "\n",
      "Zone lookup shape: (265, 4)\n",
      "Columns: ['LocationID', 'Borough', 'Zone', 'service_zone']\n"
     ]
    }
   ],
   "source": [
    "# Validate that the downloads completed successfully\n",
    "for label, path in [(\"Trip data\", TRIP_DATA_PATH), (\"Zone lookup\", ZONE_LOOKUP_PATH)]:\n",
    "    if os.path.exists(path):\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "        print(f\"{label}: {path} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"{label}: {path} NOT FOUND!\")\n",
    "\n",
    "# Validate parquet file is readable\n",
    "df_raw = pd.read_parquet(TRIP_DATA_PATH)\n",
    "print(f\"\\nTrip dataset shape: {df_raw.shape}\")\n",
    "print(f\"Columns: {list(df_raw.columns)}\")\n",
    "\n",
    "# Validate zone lookup CSV\n",
    "zone_df = pd.read_csv(ZONE_LOOKUP_PATH)\n",
    "print(f\"\\nZone lookup shape: {zone_df.shape}\")\n",
    "print(f\"Columns: {list(zone_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf80c1",
   "metadata": {},
   "source": [
    "### 3. File Organisation & Initial Inspection\n",
    "Save downloaded files to a data/raw/ directory. Include a .gitignore file that excludes the data directory from version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11dd2198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ directory structure:\n",
      "data/\n",
      "  raw/\n",
      "    taxi_zone_lookup.csv (0.01 MB)\n",
      "    yellow_tripdata_2024-01.parquet (47.65 MB)\n",
      "\n",
      "--- Data Types ---\n",
      "VendorID                          int32\n",
      "tpep_pickup_datetime     datetime64[us]\n",
      "tpep_dropoff_datetime    datetime64[us]\n",
      "passenger_count                 float64\n",
      "trip_distance                   float64\n",
      "RatecodeID                      float64\n",
      "store_and_fwd_flag               object\n",
      "PULocationID                      int32\n",
      "DOLocationID                      int32\n",
      "payment_type                      int64\n",
      "fare_amount                     float64\n",
      "extra                           float64\n",
      "mta_tax                         float64\n",
      "tip_amount                      float64\n",
      "tolls_amount                    float64\n",
      "improvement_surcharge           float64\n",
      "total_amount                    float64\n",
      "congestion_surcharge            float64\n",
      "Airport_fee                     float64\n",
      "dtype: object\n",
      "\n",
      "--- First 5 Rows ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 00:57:55</td>\n",
       "      <td>2024-01-01 01:17:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:03:00</td>\n",
       "      <td>2024-01-01 00:09:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:17:06</td>\n",
       "      <td>2024-01-01 00:35:01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:36:38</td>\n",
       "      <td>2024-01-01 00:44:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:46:51</td>\n",
       "      <td>2024-01-01 00:52:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2024-01-01 00:57:55   2024-01-01 01:17:43              1.0   \n",
       "1         1  2024-01-01 00:03:00   2024-01-01 00:09:36              1.0   \n",
       "2         1  2024-01-01 00:17:06   2024-01-01 00:35:01              1.0   \n",
       "3         1  2024-01-01 00:36:38   2024-01-01 00:44:56              1.0   \n",
       "4         1  2024-01-01 00:46:51   2024-01-01 00:52:57              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           1.72         1.0                  N           186            79   \n",
       "1           1.80         1.0                  N           140           236   \n",
       "2           4.70         1.0                  N           236            79   \n",
       "3           1.40         1.0                  N            79           211   \n",
       "4           0.80         1.0                  N           211           148   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2         17.7    1.0      0.5        0.00           0.0   \n",
       "1             1         10.0    3.5      0.5        3.75           0.0   \n",
       "2             1         23.3    3.5      0.5        3.00           0.0   \n",
       "3             1         10.0    3.5      0.5        2.00           0.0   \n",
       "4             1          7.9    3.5      0.5        3.20           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0         22.70                   2.5          0.0  \n",
       "1                    1.0         18.75                   2.5          0.0  \n",
       "2                    1.0         31.30                   2.5          0.0  \n",
       "3                    1.0         17.00                   2.5          0.0  \n",
       "4                    1.0         16.10                   2.5          0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"data/ directory structure:\")\n",
    "for root, dirs, files in os.walk(\"data\"):\n",
    "    level = root.replace(\"data\", \"\").count(os.sep)\n",
    "    indent = \"  \" * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    for f in files:\n",
    "        size_mb = os.path.getsize(os.path.join(root, f)) / (1024 * 1024)\n",
    "        print(f\"{indent}  {f} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\n--- Data Types ---\")\n",
    "print(df_raw.dtypes)\n",
    "\n",
    "print(\"\\n--- First 5 Rows ---\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55414b3",
   "metadata": {},
   "source": [
    "## _**Part 2: Data Transformation & Analysis**_\n",
    "This part covers Data Cleaning, Feature Engineering, Saving the Processed Dataset, and Running SQL queries with DuckDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d85254d",
   "metadata": {},
   "source": [
    "### 4. Data Cleaning\n",
    "\n",
    "    e) Removing rows with null values in critical columns (pickup/dropoff times, locations,\n",
    "    fare)\n",
    "\n",
    "    f) Filtering out invalid trips: trips with zero or negative distance, negative fares, or fares\n",
    "    exceeding $500\n",
    "\n",
    "    g) Removing trips where dropoff time is before pickup time\n",
    "\n",
    "    h) Documenting how many rows were removed and why (print summary to console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "initial_rows = len(df)\n",
    "\n",
    "# Ensure datetime columns are proper datetime type\n",
    "df[\"tpep_pickup_datetime\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"])\n",
    "df[\"tpep_dropoff_datetime\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
    "\n",
    "# 1. Remove rows outside January 2024\n",
    "df = df[\n",
    "    (df[\"tpep_pickup_datetime\"] >= \"2024-01-01\")\n",
    "    & (df[\"tpep_pickup_datetime\"] < \"2024-02-01\")\n",
    "]\n",
    "print(f\"After date filter: {len(df):,} rows (removed {initial_rows - len(df):,})\")\n",
    "\n",
    "# 2. Remove rows where dropoff is before pickup\n",
    "df = df[df[\"tpep_dropoff_datetime\"] > df[\"tpep_pickup_datetime\"]]\n",
    "print(f\"After dropoff > pickup filter: {len(df):,} rows\")\n",
    "\n",
    "# 3. Remove non-positive distances and fares\n",
    "df = df[df[\"trip_distance\"] > 0]\n",
    "df = df[df[\"fare_amount\"] > 0]\n",
    "df = df[df[\"total_amount\"] > 0]\n",
    "print(f\"After positive distance/fare filter: {len(df):,} rows\")\n",
    "\n",
    "# 4. Remove unreasonably long trips (> 200 miles or > 5 hours)\n",
    "df[\"trip_duration_min\"] = (\n",
    "    (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]).dt.total_seconds() / 60\n",
    ")\n",
    "df = df[df[\"trip_distance\"] <= 200]\n",
    "df = df[df[\"trip_duration_min\"] <= 300]  # 5 hours max\n",
    "df = df[df[\"trip_duration_min\"] >= 1]    # at least 1 min\n",
    "print(f\"After duration/distance cap: {len(df):,} rows\")\n",
    "\n",
    "# 5. Remove unreasonable passenger counts\n",
    "df = df[(df[\"passenger_count\"] >= 1) & (df[\"passenger_count\"] <= 9)]\n",
    "print(f\"After passenger count filter: {len(df):,} rows\")\n",
    "\n",
    "# Summary\n",
    "removed = initial_rows - len(df)\n",
    "print(f\"\\n--- Cleaning Summary ---\")\n",
    "print(f\"Original rows:  {initial_rows:,}\")\n",
    "print(f\"Cleaned rows:   {len(df):,}\")\n",
    "print(f\"Removed:        {removed:,} ({removed/initial_rows*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a49c314",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering\n",
    "\n",
    "    i) trip_duration_minutes: calculated from pickup and dropoff timestamps\n",
    "\n",
    "    j) trip_speed_mph: distance divided by duration (handle division by zero)\n",
    "\n",
    "    k) pickup_hour: hour of day (0-23) extracted from pickup timestamp\n",
    "\n",
    "    l) pickup_day_of_week: day name (Monday-Sunday) extracted from pickup\n",
    "    timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00cd19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract useful time features\n",
    "df[\"pickup_hour\"] = df[\"tpep_pickup_datetime\"].dt.hour\n",
    "df[\"pickup_day_of_week\"] = df[\"tpep_pickup_datetime\"].dt.day_name()\n",
    "df[\"pickup_date\"] = df[\"tpep_pickup_datetime\"].dt.date\n",
    "\n",
    "# Speed in mph (distance / duration in hours)\n",
    "df[\"avg_speed_mph\"] = df[\"trip_distance\"] / (df[\"trip_duration_min\"] / 60)\n",
    "\n",
    "# Cap unreasonable speeds (> 80 mph is not realistic in NYC)\n",
    "df.loc[df[\"avg_speed_mph\"] > 80, \"avg_speed_mph\"] = np.nan\n",
    "\n",
    "# Tip percentage\n",
    "df[\"tip_pct\"] = np.where(\n",
    "    df[\"fare_amount\"] > 0,\n",
    "    (df[\"tip_amount\"] / df[\"fare_amount\"]) * 100,\n",
    "    0,\n",
    ")\n",
    "\n",
    "print(\"New features added:\")\n",
    "print(df[[\"pickup_hour\", \"pickup_day_of_week\", \"pickup_date\", \"trip_duration_min\", \"avg_speed_mph\", \"tip_pct\"]].head(10))\n",
    "print(f\"\\nDataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5642666",
   "metadata": {},
   "source": [
    "### Save Cleaned Dataset\n",
    "Save the processed DataFrame as a parquet file for the Streamlit dashboard to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = os.path.join(\"data\", \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "clean_path = os.path.join(PROCESSED_DIR, \"yellow_2024_01_clean.parquet\")\n",
    "df.to_parquet(clean_path, index=False)\n",
    "\n",
    "size_mb = os.path.getsize(clean_path) / (1024 * 1024)\n",
    "print(f\"Cleaned dataset saved to {clean_path} ({size_mb:.1f} MB)\")\n",
    "print(f\"{len(df):,} rows × {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7383c",
   "metadata": {},
   "source": [
    "### 6. DuckDB SQL Analysis\n",
    "Register the cleaned DataFrame as a DuckDB table and run 5 analytical queries. DuckDB lets us write SQL directly against Pandas DataFrames without a separate database server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de00cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an in-memory DuckDB connection and register the DataFrame\n",
    "con = duckdb.connect()\n",
    "con.register(\"trips\", df)\n",
    "con.register(\"zones\", zone_df)\n",
    "\n",
    "# Quick check\n",
    "result = con.execute(\"SELECT COUNT(*) AS total_trips FROM trips\").fetchdf()\n",
    "print(f\"Trips registered in DuckDB: {result['total_trips'].iloc[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052bba05",
   "metadata": {},
   "source": [
    "#### Query 1: Top 10 Busiest Pickup Zones (Number 6 - part m)\n",
    "Which pickup zones generate the most trips? Joining with the zone lookup table to get human-readable zone names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2024e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        z.Zone,\n",
    "        z.Borough,\n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(t.total_amount), 2) AS avg_total\n",
    "    FROM trips t\n",
    "    JOIN zones z ON t.PULocationID = z.LocationID\n",
    "    GROUP BY z.Zone, z.Borough\n",
    "    ORDER BY trip_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Query 1: Top 10 Busiest Pickup Zones\")\n",
    "q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3314d",
   "metadata": {},
   "source": [
    "#### Query 2: Average Fare and Distance by Hour of Day (Number 6 - part n)\n",
    "Do fares and distances vary throughout the day? This helps understand peak pricing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df98a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        pickup_hour,\n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(fare_amount), 2) AS avg_fare,\n",
    "        ROUND(AVG(trip_distance), 2) AS avg_distance,\n",
    "        ROUND(AVG(trip_duration_min), 2) AS avg_duration_min\n",
    "    FROM trips\n",
    "    GROUP BY pickup_hour\n",
    "    ORDER BY pickup_hour\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Query 2: Average Fare and Distance by Hour of Day\")\n",
    "q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e2952",
   "metadata": {},
   "source": [
    "#### Query 3: Payment Type Distribution (Number 6 - part o)\n",
    "How do passengers pay? Breaking down by payment type with revenue contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b386603",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        CASE payment_type\n",
    "            WHEN 1 THEN 'Credit Card'\n",
    "            WHEN 2 THEN 'Cash'\n",
    "            WHEN 3 THEN 'No Charge'\n",
    "            WHEN 4 THEN 'Dispute'\n",
    "            ELSE 'Unknown'\n",
    "        END AS payment_method,\n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(SUM(total_amount), 2) AS total_revenue,\n",
    "        ROUND(AVG(tip_amount), 2) AS avg_tip,\n",
    "        ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) AS pct_of_trips\n",
    "    FROM trips\n",
    "    GROUP BY payment_type\n",
    "    ORDER BY trip_count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Query 3: Payment Type Distribution\")\n",
    "q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe4edf",
   "metadata": {},
   "source": [
    "#### Query 4: Daily Trip Volume and Revenue (Number 6 - part p)\n",
    "Day-by-day trends for January 2024 — helps spot weekday vs. weekend patterns and any anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d911561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        pickup_date,\n",
    "        pickup_day_of_week AS day_name,\n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(SUM(total_amount), 2) AS total_revenue,\n",
    "        ROUND(AVG(trip_distance), 2) AS avg_distance\n",
    "    FROM trips\n",
    "    GROUP BY pickup_date, pickup_day_of_week\n",
    "    ORDER BY pickup_date\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Query 4: Daily Trip Volume and Revenue (first 10 days)\")\n",
    "q4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0682bd",
   "metadata": {},
   "source": [
    "#### Query 5: Trip Characteristics by Day of Week (Number 6 - part q)\n",
    "Comparing weekday vs. weekend travel behaviour: average speed, distance, fare, and tip percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5 = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        pickup_day_of_week AS day_name,\n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(trip_distance), 2) AS avg_distance,\n",
    "        ROUND(AVG(fare_amount), 2) AS avg_fare,\n",
    "        ROUND(AVG(tip_pct), 2) AS avg_tip_pct,\n",
    "        ROUND(AVG(avg_speed_mph), 2) AS avg_speed\n",
    "    FROM trips\n",
    "    GROUP BY pickup_day_of_week\n",
    "    ORDER BY\n",
    "        CASE pickup_day_of_week\n",
    "            WHEN 'Monday' THEN 1\n",
    "            WHEN 'Tuesday' THEN 2\n",
    "            WHEN 'Wednesday' THEN 3\n",
    "            WHEN 'Thursday' THEN 4\n",
    "            WHEN 'Friday' THEN 5\n",
    "            WHEN 'Saturday' THEN 6\n",
    "            WHEN 'Sunday' THEN 7\n",
    "        END\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Query 5: Trip Characteristics by Day of Week\")\n",
    "q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b185ff9",
   "metadata": {},
   "source": [
    "## Part 3: Visualization Prototypes\n",
    "Below are prototypes of all 5 visualizations using Plotly. These are the same charts that appear in the Streamlit dashboard (pages/2_Visualizations.py), but rendered here in the notebook for development and grading purposes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
